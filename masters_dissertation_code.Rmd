---
title: "UCT Masters Minor Disseration"
author: "Gustav Oosthuizen"
date: "22/09/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Importing/Loading packages

```{r, importing/loading packages}

# 1. General workflow
library(tidyverse)
library(stringr)
library(lubridate)
library(stringr)


# 2. Network Analytics
library(igraph)
library(Matrix)

# 3. ML packages
library(caret)
library(glmnet)
library(ROCR)

```

# 1. Loading data

```{r, loading data}

# Note: There is three separate data files: i) accounts, ii) alerts, iii) transactions

# 1. Training data
training_accounts_raw <- read.csv("training_set_all_ml_typologies/accounts.csv")
training_transactions_raw <- read.csv("training_set_all_ml_typologies/transactions.csv")
training_alert_accounts_raw <- read.csv("training_set_all_ml_typologies/alert_accounts.csv")
training_alert_transactions_raw <- read.csv("training_set_all_ml_typologies/alert_transactions.csv")

# 1. Training data
testing_accounts_raw <- read.csv("testing_set_all_ml_typologies/accounts.csv")
testing_transactions_raw <- read.csv("testing_set_all_ml_typologies/transactions.csv")
testing_alert_accounts_raw <- read.csv("testing_set_all_ml_typologies/alert_accounts.csv")
testing_alert_transactions_raw <- read.csv("testing_set_all_ml_typologies/alert_transactions.csv")


### BASIC STATS - test train ###

# fraud transactions
table(training_transactions_raw$is_sar)
# 0.1% fraud transactions

table(testing_transactions_raw$is_sar)
# 0.05% fraud transactions


# fraud alerts
table(training_alert_transactions_raw$alert_type)/sum(table(training_alert_transactions_raw$alert_type))*100


table(testing_alert_transactions_raw$alert_type)/sum(table(testing_alert_transactions_raw$alert_type))*100

###  SAMPLE NETORK DATA SET ###

# Constructing sample network used by Bart Baesens et al. (Fraud Analytics book) - Undirected network & Undirected weighted network


# 1. Configuring sample edge and node df's

# nodes (i.e customer's accounts)
# node_df <- data.frame(client_ID = LETTERS[1:20],
#                       is_fraud = c(rep(F, 3), T, T, T, rep(F,2), T, rep(F,11)))

# edges (i.e customers transactions)
# edge_df <- data.frame(from = c("A","A", "A", "A", "A", "A", "D", "D", "D", "D", "Q", "Q", "Q", "N","N", "N", "I", "I", "K", "K", "O", "B", "F", "F", "M"),
#                       to = c("I", "T", "B", "H", "O", "G", "G", "B", "E", "F", "R", "S", "O", "M", "L", "I", "K", "G", "J", "H", "P", "C", "G", "E", "L"),
#                       weight = c(rexp(10,0.001), rep(1000,10), rexp(5,0.001)))


# 2. Building sample network

# 2.1 un- directed network
# sample_network_undirected <- graph_from_data_frame(d = edge_df[,-3], # removing weight col
#                                  vertices = node_df,
#                                  directed = FALSE)


# 2.2 un-directed weighted network
# sample_network_undirected_weighted <- graph_from_data_frame(d = edge_df,
#                                  vertices = node_df,
#                                  directed = FALSE)

# 2.3 directed network
# sample_network_directed_weighted <- graph_from_data_frame(d = edge_df, # removing weight col
#                                  vertices = node_df,
#                                  directed = TRUE)


# visualizing the graph (only directed graph)

# fraud_colour <- if_else(V(sample_network_directed_weighted)$is_fraud == T, "red", "green")
# V(sample_network_directed_weighted)$color <- fraud_colour
# E(sample_network_directed_weighted)$width <- E(sample_network_directed_weighted)$weight/200
# plot(sample_network_directed_weighted)

# interactive plot

# tkid <- tkplot(sample_network_directed_weighted) #tkid is the id of the tkplot that will open
# l <- tkplot.getcoords(sample_network_directed_weighted)


```

# 2. Pre-local-EDA of each raw data table

```{r, prelimimary exploratory data analysis of each data set }


# Note: some of the plots and stats can be useful

### KAGGLE DATA SET (OLD) ###

# 1. Accounts data

# 1.1 structure

str(accounts_data_raw)

summary(accounts_data_raw)

# 1.2 Checking uniqueness of variables

accounts_data_raw$ACCOUNT_ID %>% 
  unique() %>% 
  length()

# Note: there are 1000 accounts

accounts_data_raw$CUSTOMER_ID %>% 
  unique() %>% 
  length()

# Note: It seems like the assumption was made that the a customer only has one account.

accounts_data_raw$COUNTRY %>% 
  unique() 

# Seems like the only country is US

accounts_data_raw$ACCOUNT_TYPE %>% 
  unique()

# plotting fraudulent and not fraudent accounts

accounts_data_raw %>% 
  group_by(IS_FRAUD) %>% 
  summarise(total_count = n()) %>% 
  ggplot(aes(y = total_count, x = IS_FRAUD, fill = IS_FRAUD)) + 
  geom_col() + 
  geom_text(aes(label = total_count), vjust = 1)


# 17% is fraudulent accounts and the 83% are honest users

# plot of accounts distribution

# box and whiskers plot - initial balance

ggplot(accounts_data_raw, aes(y = IS_FRAUD, x = INIT_BALANCE)) +
  geom_boxplot()

# distribution plots

# histogram
ggplot(accounts_data_raw, aes(x = INIT_BALANCE, fill = IS_FRAUD)) +
  geom_histogram() +
  facet_wrap(~IS_FRAUD)

# density plot
ggplot(accounts_data_raw, aes(x = INIT_BALANCE, fill = IS_FRAUD)) +
  geom_density() +
  facet_wrap(~IS_FRAUD)

# 2. alerts 

str(alerts_data_raw)

summary(alerts_data_raw)

# Checking the uniqueness of each column

sapply(alerts_data_raw[sapply(alerts_data_raw, class) == "character"], unique)


# plot of alerts distribution

# box and whiskers plot - transaction amount

ggplot(alerts_data_raw, aes(x = TX_AMOUNT, y = IS_FRAUD)) +
  geom_boxplot()

# distribution - transaction amount

# histogram
ggplot(alerts_data_raw, aes(x = TX_AMOUNT)) +
  geom_histogram()

# density plot
ggplot(alerts_data_raw, aes(x = TX_AMOUNT)) +
  geom_density()

# time series plot

alerts_data_raw %>% 
ggplot(aes(x = TIMESTAMP, y = TX_AMOUNT)) + 
  geom_jitter()

# Note: No transactions were flagged that had a amount between 5 and 10 interesting to note that 

#  Histogram of received accounts

alerts_data_raw %>% 
  group_by(RECEIVER_ACCOUNT_ID) %>% 
  summarise(total_count = n()) %>% 
  arrange(desc(total_count)) %>% 
  ggplot(aes(x = total_count)) +
  geom_histogram()

#  Histogram of sender accounts

alerts_data_raw %>% 
  group_by(SENDER_ACCOUNT_ID) %>% 
  summarise(total_count = n()) %>% 
  arrange(desc(total_count)) %>% 
  ggplot(aes(x = total_count)) +
  geom_histogram()


# Count plot of the number of alert types

alerts_data_raw %>% 
  group_by(ALERT_TYPE) %>% 
  summarise(total_count = n()) %>% 
  ggplot(aes(y = total_count, x = ALERT_TYPE, fill = ALERT_TYPE)) + 
  geom_col() + 
  geom_text(aes(label = total_count), vjust = 1)


# 2. Transactions

# structure

str(transactions_data_raw)


# classes of variables

sapply(transactions_data_raw[sapply(transactions_data_raw, class) == "character"], unique)

# distributions - transactions

# box and whiskers plot
ggplot(transactions_data_raw, aes(x = TX_AMOUNT, y = IS_FRAUD)) +
  geom_boxplot() +
  scale_x_continuous(trans='log10')

# histogram
ggplot(transactions_data_raw, aes(x = TX_AMOUNT, fill = IS_FRAUD)) +
  geom_histogram() +
  facet_wrap(~IS_FRAUD) +
  scale_x_continuous(trans='log10') + 
  scale_y_continuous(trans='log10')

# density plots - fraud transactions

transactions_data_fraud <- transactions_data_raw %>% 
  filter(IS_FRAUD == "True")

# maximum density occurs at tx value of:
mode_tx_fraud <- density(transactions_data_fraud$TX_AMOUNT)$x[which.max(density(transactions_data_fraud$TX_AMOUNT)$y)]


ggplot(transactions_data_fraud, aes(TX_AMOUNT)) + 
  geom_density() + 
  geom_vline(xintercept = mode_tx_fraud)

# density plots - Non-fraud transactions (NB! something weird is heaping here!)

transactions_data_honest <- transactions_data_raw %>% 
  filter(IS_FRAUD == "False",
         TX_AMOUNT != 0)

# maximum density occurs at tx value of:
# which.max(density(transactions_data_honest$TX_AMOUNT)$y)
# 
# ggplot(transactions_data_honest, aes(TX_AMOUNT)) + 
#   geom_density() + 
#   geom_vline(xintercept = mode_tx_honest) + 
#   scale_x_log10()


         
```

# 3. Feature Extraction

# 3.1 Data pre-processing, data split and checks

```{r, data pre-processing and checks}

# 1. Data preparations

# 1.1 Defining needed data-pre processing functions
# Note: The following function removes and renames the the accounts raw data such that it is ready for downstream processes

# accounts data table

accounts_data_prep_func <- function(accounts_data_raw) {
  
  # 1. selecting variables and renaming them
  
  accounts_data_up <- accounts_data_raw %>% 
    select(acct_id, prior_sar_count, initial_deposit ) %>% 
     rename(client_ID = acct_id,
           is_fraud = prior_sar_count,
           init_balance = initial_deposit) %>% 
    mutate(is_fraud = if_else(is_fraud == "false", F, T))
  
  return(accounts_data_up)
}

# transaction data table

transactions_data_prep_func <- function(transactions_data_raw) {
  
  # 1. selecting variables and renaming them
  
  transactions_data_up <- transactions_data_raw %>% 
    select(orig_acct, bene_acct,base_amt) %>% 
     rename(from = orig_acct,
           to = bene_acct,
           weight = base_amt)
  
  return(transactions_data_up)
  
}

# 2. Applying data pre-processing functions

# training
training_transactions_final <- transactions_data_prep_func(training_transactions_raw)
training_accounts_final <- accounts_data_prep_func(training_accounts_raw)

# testing
testing_transactions_final <- transactions_data_prep_func(testing_transactions_raw)
testing_accounts_final <- accounts_data_prep_func(testing_accounts_raw)


### KAGGLE DATA SET (OLD) ###

# 1. Data preparation

# 1.1 transactions data & alerts data 

# joining alert type col from alerts df to transactions df 
# alerts_types <- alerts_data_raw %>% 
#   select(ALERT_ID, ALERT_TYPE)
# 
# transactions_data_up <- transactions_data_raw %>% 
#   left_join(alerts_types, by = "ALERT_ID") %>% 
#   unique()

# replacing NA values formed by transactions that are not fraud
# transactions_data_up[is.na(transactions_data_up)] <- "No Alert"

# rearranging columns such that sender node and receiver node is mentioned first in the df
# transactions_data_up <- transactions_data_up[,c(2,3,1,4:ncol(transactions_data_up))]

# 1.2 Selecting/renaming only needed cols for networks that will be generated

# nodes

# accounts_data_final <- accounts_data_raw %>% 
#   select(ACCOUNT_ID, INIT_BALANCE, IS_FRAUD) %>% 
#   rename(client_ID = ACCOUNT_ID,
#          is_fraud = IS_FRAUD,
#          init_balance = INIT_BALANCE) %>% 
#   mutate(is_fraud = if_else(is_fraud == "true", T, F))

# edges
# transactions_data_final <- transactions_data_raw %>% 
#   select(SENDER_ACCOUNT_ID, RECEIVER_ACCOUNT_ID, TX_AMOUNT, TIMESTAMP, IS_FRAUD) %>% 
#   rename(from = SENDER_ACCOUNT_ID,
#          to = RECEIVER_ACCOUNT_ID,
#          weight = TX_AMOUNT)


# 2. Data checks 

# 2.1 Checking when account is deemed as fraud

## sender accounts

# sender_transactions_fraud <- transactions_data_up %>% 
#   filter(IS_FRAUD == "True") %>% 
#   select(SENDER_ACCOUNT_ID) %>% 
#   unique()
# 
# receiver_transactions_fraud <- transactions_data_up %>% 
#   filter(IS_FRAUD == "False") %>% 
#   select(RECEIVER_ACCOUNT_ID) %>% 
#   unique()
# 
# clients <- accounts_data_raw %>%
#   select(IS_FRAUD, ACCOUNT_ID) %>% 
#   mutate(sender_account = ACCOUNT_ID %in% sender_transactions_fraud$SENDER_ACCOUNT_ID) %>% 
#   mutate(receiver_account = ACCOUNT_ID %in% receiver_transactions_fraud$RECEIVER_ACCOUNT_ID) %>% 
#   mutate(logic_tester = if_else(((sender_account = T) | (receiver_account = T)) & IS_FRAUD != "true", "Not Valid", "Valid"))
# 
# 
# not_valid_clients <- clients %>% 
#   filter(logic_tester == "Not Valid")

# Conclusion: NB! An account is deemed fraudulent if it is a recipient or sender of a flagged fraudulent transaction. 

# 2.2 Checking if there are any repetitions in node and edge df's

# nodes - accounts
# nrow(accounts_data_raw)
# 
# accounts_data_raw$ACCOUNT_ID %>%
#   unique() %>% 
#   length()
  
# Note: there are 1000 different accounts

# 2.2 links - transactions

# nrow(transactions_data_up)
# 
# nrow(unique(transactions_data_up[,c("SENDER_ACCOUNT_ID", "RECEIVER_ACCOUNT_ID")]))

# Note: There are more links than sender-receiver combination, therefore we have cases where there is multiple links between the same nodes. This will be adresed in the next code section.


```

# 3.2 Network construction - Undirected weighted network (simplified) function(s)

*Note:* The simplified graph will only consider one edge between incident nodes.

```{r, network construction and feature extraction - undirected weighted network (simplified) }

#### Un-directed weighted Network feature generation function ####

# Description: The function will take as input a sub-graph with more than 2 nodes and calculate the relevant network metrics.

# input: a weighted undirected sub-graph with more than two nodes
# output: a data frame containing all the network metrics extracted from the sub-graph. 

# NB! The function will only  be able to take as input an un-directed-weighted network.


# 1. Defining additional functions that will be used within the network feature generation function

# 1.1 Degree functions

# 1.1.1 Fraud degree calculations
fraud_degree_counter_func <- function(graph){
  
  # names of all the nodes in the network
  node_names <- V(graph)$name 
  
  # creating variable to store fraud degree counts for each node
  fraud_degree_vec <- rep(NA, length(node_names))
  
  # looping to calculate for each fraud degree
  for (i in 1:length(node_names)) {
    
    # extracting temp sub-graph for a single node
    temp_sub_graph <- induced_subgraph(graph, 
                                       vids = unlist(neighborhood(graph = graph, order = 1, nodes = node_names[i])),
                                       impl = "auto")
    
    # converting sub-graph to data_frame and filtering
    temp_fraud_degree <- as_data_frame(temp_sub_graph, what = "vertices") %>% 
      filter(name != node_names[i] & is_fraud == T) %>% 
      nrow()
    
    # saving fraud degree
    fraud_degree_vec[i] <- temp_fraud_degree
    
  }
  
  return(fraud_degree_vec)
  
}

# 1.1.2  Non-fraud degree calculations
non_fraud_degree_counter_func <- function(graph){
  
  # names of all the nodes in the network
  node_names <-V(graph)$name 
  
  # creating variable to store fraud degree counts for each node
  non_fraud_degree_vec <- rep(NA, length(node_names))
  
  # looping to calculate for each fraud degree
  for (i in 1:length(node_names)) {
    
    # extracting temp sub-graph for a single node
    temp_sub_graph <- induced_subgraph(graph, 
                                       vids = unlist(neighborhood(graph = graph, order = 1, nodes = node_names[i])),
                                       impl = "auto")
    
    # converting sub-graph to data_frame and filtering
    temp_non_fraud_degree <- as_data_frame(temp_sub_graph, what = "vertices") %>% 
      filter(name != node_names[i] & is_fraud == F) %>% 
      nrow()
    
    # saving fraud degree
    non_fraud_degree_vec[i] <- temp_non_fraud_degree
    
  }
  
  return(non_fraud_degree_vec)
  
}


# 1.2 Node density function

node_density_func <- function(graph) {
  
  # names of all the nodes in the network
  node_names <-V(graph)$name 
  
  # creating variable to store fraud degree counts for each node
  node_density_vec <- rep(NA, length(node_names))
  
  # looping to calculate for each fraud degree
  for (i in 1:length(node_names)) {
    
    # extracting temp sub-graph for a single node
    temp_sub_graph <- induced_subgraph(graph, 
                                       vids = unlist(neighborhood(graph = graph, order = 1, nodes = node_names[i])),
                                       impl = "auto")
    # calculating density and saving value
    node_density_vec[i] <- edge_density(temp_sub_graph)
    
  }
  
  return(node_density_vec)
  
}

# 1.3 Relational neighbor (classifier)

relational_neighbour_classifier_func <- function(graph) {
  
  # names of all the nodes in the network
  node_names <-V(graph)$name 
  
  # creating variable to store the probability of node being fraudulent or non-fraudulent according to its neighborhood
  prob_fraud_vec <- rep(NA, length(node_names))
  prob_non_fraud_vec <- rep(NA, length(node_names))
  
  # looping to calculate for each fraud degree
  
  for (i in 1:length(node_names)) {
    
    # extracting temp sub-graph for a single node
    temp_sub_graph <- induced_subgraph(graph, 
                                       vids = unlist(neighborhood(graph = graph, order = 1, nodes = node_names[i])),
                                       impl = "auto")
    
    # converting sub-graph to data_frame and filtering
    temp_df <- as_data_frame(temp_sub_graph, what = "vertices")
    
    # calculating number of # fraud neighbors
    temp_count_fraud <- temp_df %>% 
      filter(name != node_names[i] & is_fraud == T) %>% 
      nrow()
    
    # calculating number of # non-fraud neighbors
    temp_count_non_fraud <- temp_df %>% 
      filter(name != node_names[i] & is_fraud == F) %>% 
      nrow()
    
    # calculating nrmalisation factor (Z)
    Z =  temp_count_fraud + temp_count_non_fraud
    
    prob_fraud_vec[i] <- temp_count_fraud/Z
    
    prob_non_fraud_vec[i] <- temp_count_non_fraud/Z
    
    }
  
  probability_res <- list(prob_fraud = prob_fraud_vec,
                          prob_non_fraud = prob_non_fraud_vec) 
  
  
  return(probability_res)
  
}

# 1.4 Probabilistic relational neighbor (classifier)

prob_relational_neighbor_classifier_func <- function(graph, relational_neig_prob_fraud, relational_neig_prob_non_fraud){
  
  # adding relational neighborhood classifier results to graph
  V(graph)$relational_neig_prob_fraud <- relational_neig_prob_fraud
  V(graph)$relational_neig_prob_non_fraud <- relational_neig_prob_non_fraud
  
  # names of all the nodes in the network
  node_names <-V(graph)$name 
  
  # creating variable to store the probability of node being fraudulent or non-fraudulent according to its neighborhood
  prob_fraud_vec <- rep(NA, length(node_names))
  prob_non_fraud_vec <- rep(NA, length(node_names))
  
  # looping to calculate for each fraud degree
  for (i in 1:length(node_names)) {
    
    # extracting temp sub-graph for a single node
    temp_sub_graph <- induced_subgraph(graph, 
                                       vids = unlist(neighborhood(graph = graph, order = 1, nodes = node_names[i])),
                                       impl = "auto")
    
    # converting sub-graph to data_frame and filtering
    temp_df <- as_data_frame(temp_sub_graph, what = "vertices")
    
    # calculating number of # fraud neighbors
    temp_count_fraud <- temp_df %>% 
      filter(name != node_names[i]) %>% 
      select(relational_neig_prob_fraud) %>% 
      sum()
    
    # calculating number of # non-fraud neighbors
    temp_count_non_fraud <- temp_df %>% 
      filter(name != node_names[i]) %>% 
      select(relational_neig_prob_non_fraud) %>% 
      sum()
    
    # calculating normalization factor (Z)
    Z =  temp_count_fraud + temp_count_non_fraud
    
    prob_fraud_vec[i] <- temp_count_fraud/Z
    
    prob_non_fraud_vec[i] <- temp_count_non_fraud/Z
    
  }
    

  
  probability_res <- list(prob_fraud = prob_fraud_vec,
                          prob_non_fraud = prob_non_fraud_vec) 
  
}

# 1.5 Calculating, Fraud, Semi-Fraud, and Legit triangles

# The function below classifies all the triangles found in a network as either being legit, fraud or semi-fraud
triangle_classifier_func <- function(graph){
  
  
  if(sum(count_triangles(graph)) > 0){
  
  # calculates the complete sub-graphs with 3 vertices (i.e triangles)
  cl.tri = cliques(graph,
                   min=3,
                   max=3)
  
  # constructing a data frame where each row corresponds to a triangle and each column to a node in that triangle
  df <- lapply(cl.tri, function(x){V(graph)$name[x]})
  triangles_df = data.frame(matrix(unlist(df),ncol=3,byrow=T))
  
  # creating class label for triangles (will be important later)
  triangles_df$triangle_label <- rep(NA,nrow(triangles_df))
  
  # creating a sub graph for each triangle
  for (i in 1:nrow(triangles_df)) {
    
    # counting fraud triangles
    temp_triangle <- c(triangles_df$X1[i], triangles_df$X2[i], triangles_df$X3[i])
    
    # creating sub_graph
    temp_sub_graph <- induced_subgraph(graph, 
                                       vids = temp_triangle, # triangle nodes
                                       impl = "auto")
    
    fraud_sum <- as_data_frame(temp_sub_graph, what = "vertices") %>% 
      select(is_fraud) %>% 
      sum()
    
    
    if(fraud_sum == 0){
      
      triangles_df$triangle_label[i] <- "legit_triangles"
      
    }else if(fraud_sum == 1 | fraud_sum == 2){
      
      triangles_df$triangle_label[i] <- "semi_fraud_triangles"
    }else{
      
      triangles_df$triangle_label[i] <- "fraud_triangles"
      
      } 
  }
  
  # changing df in long format
  triangles_df_long <- pivot_longer(triangles_df,
                                        cols = 1:3,
                                        names_to = "col_names",
                                        values_to = "client_ID"
                                        ) %>% 
  select(-col_names)
  
  # tabulating triangles result
  triangles_df_table_long <-  as.data.frame(t(table(triangles_df_long)))
  
  # converting to wide format
  triangles_df <- pivot_wider(triangles_df_table_long,
                              names_from = triangle_label,
                              values_from = Freq)
  
  }else{
    
   number_vertices <-  vcount(graph)  
   null_traingle_df <- as.data.frame(matrix(0, number_vertices, 3)) %>% 
     rename(legit_triangles = V1,
            semi_fraud_triangles = V2,
            fraud_triangles = V3)
   
   client_ID <- V(graph)$name
   
   triangles_df <- cbind(client_ID, null_traingle_df)
   
   }
  
  
  return(triangles_df)
  
}

# 2. Defining weighted network feature generation function 


undirected_weighted_network_feature_func <- function(sub_graph, verbose = c(TRUE,FALSE)){
  
  sample_network <- sub_graph
  
  # Note: Sample network refers to the current sub-graph that is used.
  
  # 1. Extracting network metrics
  
  # 1.1 Neighborhood metrics
  
  if(verbose){print("1. Calculating neighbourhood metrics")}
  
  # 1.1.1 Transitivity - (local) ratio of triangles to connected triples each vertex is part of. Can be interpreted as a probability for the network to have adjacent nodes interconnected, thus revealing the existence of tightly connected communities (or clusters, subgroups, cliques).
  
  if(verbose){print("1.1 Calculating transitivity...")}
  
  transitivity_loc_uw <- transitivity(sample_network, 
                                      type = "local",
                                      vids = V(sample_network),
                                      isolates = "zero",
                                      weights = E(sample_network)$weight) 

  # 1.1.2 Total Degree (local) - Here the degree is defined as the number of edges between connected nodes.
  
  if(verbose){print("1.2 Calculating total degree...")}
  
  total_degree_loc_uw <- degree(sample_network, 
                                       loops = F, 
                                       mode = "all")
  # Note: Loops are not counted.
  
  # 1.1.3  Calculating fraud degree
  
  # NB! Check the name and is_fraud column in the filtering operation when bigger network is used.
  
  if(verbose){print("1.3 Calculating fraud degree...")}
  
  is_fraud_degree_loc_uw <- fraud_degree_counter_func(graph = sample_network)
  
  # 1.1.4 Calculating  Non-fraud degree
  
  if(verbose){print("1.4 Calculating non-fraud degree...")}
  
  # calculating non-fraud degree
  non_fraud_degree_loc_uw <- non_fraud_degree_counter_func(graph = sample_network)
  
  # 1.1.5 Strength (weighted degree) - Summing up the edge weights of the adjacent edges for each vertex
  
  if(verbose){print("1.5 Calculating strength...")}
  
  degree_strength_loc_uw <- strength(sample_network,
                                     loops = F,
                                     mode = "all",
                                     weights = E(sample_network)$weight # NB! will change when  weights are incorporated
  )
  
  # NB!! Try to implement degree strength for fraud and non-fraud nodes (when implementing weighted network)

  # 1.1.6  Node density: considering an each node and its neighborhood of 1, then the node density is defined as the ratio of the number of edges and the number of possible edges (which you will find in a connected graph). 
  
  if(verbose){print("1.6 Calculating node density...")}
  
  node_density_loc_uw <- node_density_func(graph = sample_network)
  
  
  # 1.1.7 Relational neighbor: Assigns a probability to node i is part of class fraud or non-fraud given the class labels of node i's neighborhood. 
  
  if(verbose){print("1.7 Calculating relational neighbour...")}
  
  # results of the relational neighborhood classifier
  relational_neig_results <- relational_neighbour_classifier_func(graph = sample_network)
  
  # probability of non-fraud
  relational_neig_prob_non_fraud_loc_uw <- relational_neig_results$prob_non_fraud
  
  # probability of fraud
  relational_neig_prob_fraud_loc_uw <- relational_neig_results$prob_fraud
  
# 1.1.8 Probabilistic relational neighbor classifier
  
  if(verbose){print("1.8 Calculating probabilistic relational neighbour...")}
  
  # results of the prob relational neighborhood classifier
  prob_relational_neig_results <- prob_relational_neighbor_classifier_func(graph = sample_network,
                                                                           relational_neig_prob_fraud = relational_neig_prob_fraud_loc_uw,
                                                                           relational_neig_prob_non_fraud = relational_neig_prob_non_fraud_loc_uw)
  
  
  # probability of non-fraud
  prob_relational_neig_prob_non_fraud_loc_uw <- prob_relational_neig_results$prob_non_fraud
  
  # probability of fraud
  prob_relational_neig_prob_fraud_loc_uw <- prob_relational_neig_results$prob_fraud
  
  
  if(verbose){print("1.9 Calculating triangles...")}
  
  # 1.1.9 Triangles - Count how many triangles a vertex is part of, in a graph, or just list the triangles of a graph.
  
  # Total triangles
  
  triangles_loc_uw <- count_triangles(sample_network)
  
  # Note: This will be the total triangles Baesens et al. (2015) broke this up into: total fraud triangles, total legit triangles, and total semi-fraud triangles. 
  
  # Calculating, Fraud, Semi-Fraud, and Legit triangles
  
  sample_triangle_df <- triangle_classifier_func(sample_network)
  
  # creating dummy data frame
  sample_triangle_df_full <- data.frame(client_ID = V(sample_network)$name)
  
  # join operation
  sample_triangle_df_full <- left_join(sample_triangle_df_full,sample_triangle_df, by = "client_ID")
  
  # replacing NA values
  sample_triangle_df_full[is.na(sample_triangle_df_full)] <- 0
  

  # 1.2 Centrality metrics
  
  if(verbose){print("2. Calculating centrality metrics")}
  
  # 1.2.1 Closeness centrality and farness - Measures the average farness (inverse distance) to all other nodes. Nodes with a high closeness score have the shortest distances to all other nodes.
  
  if(verbose){print("2.1 Calculating closeness centrality and Farness...")}
  
  centrality_closeness_loc_uw <- closeness(sample_network,
                                           normalized = T, # can think of using TRUE on full network
                                           weights = E(sample_network)$weight) # Can use weights in full network  
  
  
  farness_loc_uw <- (centrality_closeness_loc_uw)^-1
  
  
  # 1.2.2 Eigenvector centrality - Eigenvector centrality scores correspond to the values of the first eigenvector of the graph adjacency matrix; these scores may, in turn, be interpreted as arising from a reciprocal process in which the centrality of each actor is proportional to the sum of the centralities of those actors to whom he or she is connected.
  
  if(verbose){print("2.2 Calculating eigenvector centrality...")}
  
  centrality_eigen_loc_uw_res <- eigen_centrality(sample_network,
                                              scale = T,
                                              directed = F,
                                              weights = E(sample_network)$weight) #weights can be included 
  
  centrality_eigen_loc_uw <- centrality_eigen_loc_uw_res$vector
  
  
  # 1.2.3 betweeness - the number of geodesics (shortest paths) going through a vertex or an edge
  
  if(verbose){print("2.3 Calculating betweeness...")}
  
  centrality_betweenness_loc_uw <-  betweenness(sample_network,
                                                directed = F,
                                                weights = E(sample_network)$weight,
                                                normalized = F) #weights can be included
  
  # 1.2.4  Average Geodesic - average length of all shortest paths (hops to nodes)
  
  if(verbose){print("2.4 Calculating average geodesic...")}
  
  geodesic_loc_uw <- distances(sample_network,
                                      mode = "all",
                                      weights = E(sample_network)$weight, # weights can be added 
                                      algorithm = "automatic")
  
  
  # excluding nodes that are unconnected
  avg_geodesic_loc_uw <- apply(geodesic_loc_uw, 1, mean)
  
  
  # 1.3 Inference algorithms 
  
  if(verbose){print("3. Calculating collective inference algorithms...")}
  
  # 1.3.1 PageRank
  
  # base PageRank algorithm
  pr_base_loc_uw_res <- page_rank(sample_network,
                            algo = "prpack",
                            directed = F,
                            damping = 0.85,
                            weights = E(sample_network)$weight) # can add weights 
  
  pr_base_loc_uw <- pr_base_loc_uw_res$vector
  
  # PageRank algorithm with emphasis on fraud nodes
  
  # defining start vector for algorithm (0 for legitimate clients and non-zero for fraudsters)
  total_fraud_nodes <- sum(V(sample_network)$is_fraud)

  
  # adding condition if there are any fraud nodes in the network then starting vector for page rank algorithm should be personalised
  if(total_fraud_nodes > 0){
  
  fraud_nodes_start_value <- 1/(total_fraud_nodes)
  start_vec_fraud <- if_else(V(sample_network)$is_fraud == F, 0, fraud_nodes_start_value)
  
  # calculating PageRank
  pr_fraud_loc_uw_res <- page_rank(sample_network,
                            algo = "prpack",
                            directed = F,
                            damping = 0.85,
                            personalized = start_vec_fraud,
                            weights = E(sample_network)$weight) # can add weights
  
  pr_fraud_loc_uw <- pr_fraud_loc_uw_res$vector
  
  }else{
    
  pr_fraud_loc_uw <-   pr_base_loc_uw
    
  }
  
  # 1.4 Compiling results in data frame
  
  if(verbose){print("Compiling calculated metrics in data frame...")}
  
  sample_network_feature_df <- data_frame(client_ID = V(sub_graph)$name,
                                          transitivity = transitivity_loc_uw,
                                          total_degree = total_degree_loc_uw,
                                          fraud_degree = is_fraud_degree_loc_uw,
                                          non_fraud_degree = non_fraud_degree_loc_uw,
                                          degree_strenght = degree_strength_loc_uw,
                                          node_density = node_density_loc_uw,
                                          relational_neighbour_not_fraud = relational_neig_prob_non_fraud_loc_uw,
                                          relational_neighbour_fraud = relational_neig_prob_fraud_loc_uw,
                                          probabilistic_relational_neighbour_not_fraud = prob_relational_neig_prob_non_fraud_loc_uw,
                                          probabilistic_relational_neighbour_fraud = prob_relational_neig_prob_fraud_loc_uw,
                                          total_triangles = triangles_loc_uw,
                                          legit_triangles = sample_triangle_df_full$legit_triangles,
                                          semi_fraud_triangles = sample_triangle_df_full$semi_fraud_triangles,
                                          fraud_triangles = sample_triangle_df_full$fraud_triangles,
                                          closeness_centrality = centrality_closeness_loc_uw,
                                          farness = farness_loc_uw,
                                          eigen_vector_centrality = centrality_eigen_loc_uw,
                                          betweeness = centrality_betweenness_loc_uw,
                                          avg_geodesic = avg_geodesic_loc_uw,
                                          page_rank_base = pr_base_loc_uw,
                                          page_rank_fraud = pr_fraud_loc_uw)
  

return(sample_network_feature_df)  

}

# undirected_weighted_network_feature_df <-  undirected_weighted_network_feature_func(sub_graph = sample_network_undirected_weighted, verbose = T)


```

# 3.3 Network construction - Directed network (non-simplified) function(s)

```{r, network construction - directed network (non-simplified)}

#### Directed Network feature generation function ####

# Description: The function will take as input a sub-graph with more than 2 nodes and calculate the relevant network metrics.

# input: a directed sub-graph with more than two nodes
# output: a data frame containing all the network metrics extracted from the sub-graph. 

# NB! The function will only  be able to take as input an un-directed-weighted network.

# 1. Defining additional functions that will be used within the network feature generation function

# 1.1 Degree functions

# 1.1.1 Fraud degree calculations
directed_degree_counter_func <- function(graph, fraud_selection = c(TRUE, FALSE), degree_direction = c("in", "out")){
  
  # names of all the nodes in the network
  node_names <- V(graph)$name 
  
  # creating variable to store fraud degree counts for each node
  fraud_degree_vec <- rep(NA, length(node_names))
  
  if(degree_direction == "in"){
    
    # looping to calculate for each fraud degree
    for (i in 1:length(node_names)) {
      
      # extracting temp sub-graph for a single node
      temp_sub_graph <- induced_subgraph(graph, 
                                         vids = unlist(neighborhood(graph = graph, order = 1, nodes = node_names[i])),
                                         impl = "auto")
      
      # converting sub-graph to data_frame and filtering
      temp_df <- as_data_frame(temp_sub_graph, what = "both")
      
      temp_edge_df <- temp_df$edges %>%
        rename(name = from)
      
      temp_fraud_count <- left_join(temp_edge_df,temp_df$vertices, by = "name") %>% 
        filter(name != node_names[i] & to == node_names[i] & is_fraud == fraud_selection) %>% 
        nrow() 
      
      # saving fraud degree
      fraud_degree_vec[i] <- temp_fraud_count
    }
  }
  
  if(degree_direction == "out"){
    
    # looping to calculate for each fraud degree
    for (i in 1:length(node_names)) {
      
      # extracting temp sub-graph for a single node
      temp_sub_graph <- induced_subgraph(graph, 
                                         vids = unlist(neighborhood(graph = graph, order = 1, nodes = node_names[i])),
                                         impl = "auto")
      
      # converting sub-graph to data_frame and filtering
      temp_df <- as_data_frame(temp_sub_graph, what = "both")
      
      temp_edge_df <- temp_df$edges %>%
        rename(name = to)
      
      temp_fraud_count <- left_join(temp_edge_df,temp_df$vertices, by = "name") %>% 
        filter(name != node_names[i] & from == node_names[i] & is_fraud == fraud_selection) %>% 
        nrow() 
      
      # saving fraud degree
      fraud_degree_vec[i] <- temp_fraud_count
    }
  }
  
  return(fraud_degree_vec)
  
}

# 2. Defining directed network feature generation function 

directed_network_feature_function <- function(sub_graph, verbose = c(TRUE, FALSE)){
  
  # 1. Extracting network metrics
  
  if(verbose == T){print("1. Calculating neighbourhood metrics (directed)...")}
  
  # 1.1 Neighborhood metrics
  
  if(verbose == T){print("1.1 Calculating in-degree...")}
  # 1.1.1 in-degree
  in_degree_loc_d <- degree(sub_graph, 
                            mode = "in",
                            loops = F,
                            normalized = F)
  
  if(verbose == T){print("1.2 Calculating out-degree...")}
  
  # 1.1.2 out-degree
  out_degree_loc_d <- degree(sub_graph, 
                            mode = "out",
                            loops = F,
                            normalized = F)
  
  # 1.1.3 in-degree (fraudulent/non-fraudulent clients)
  
  if(verbose == T){print("1.3 Calculating fraud in-degree...")}
  # number of transactions made by fraudulent node to the specific reference node
  in_degree_fraud_loc_d <- directed_degree_counter_func(sub_graph, fraud_selection = T, degree_direction = "in")
  
  if(verbose == T){print("1.4 Calculating non-fraud in-degree...")}
  # number of transactions made by non-fraudulent node to the specific reference node
  in_degree_non_fraud_loc_d <- directed_degree_counter_func(sub_graph, fraud_selection = F, degree_direction = "in")
  
  # 1.1.4 out-degree (fraudulent/non-fraudulent clients)
  
  if(verbose == T){print("1.5 Calculating fraud out-degree...")}
  # number of transactions made by fraudulent node to the specific reference node
  out_degree_fraud_loc_d <- directed_degree_counter_func(sub_graph, fraud_selection = T, degree_direction = "out")
  
  if(verbose == T){print("1.6 Calculating non-fraud out-degree...")}
  # number of transactions made by non-fraudulent node to the specific reference node
  out_degree_non_fraud_loc_d <- directed_degree_counter_func(sub_graph, fraud_selection = F, degree_direction = "out")
  
  
  # 1.2 Compiling results in data frame
  
  if(verbose){print("Compiling calculated metrics in data frame...")}
  
  sample_network_feature_df <- data_frame(client_ID = V(sub_graph)$name,
                                          in_degree = in_degree_loc_d,
                                          in_degree_fraud = in_degree_fraud_loc_d,
                                          in_degree_non_fraud = in_degree_non_fraud_loc_d,
                                          out_degree = out_degree_loc_d,
                                          out_degree_fraud = out_degree_fraud_loc_d,
                                          out_degree_non_fraud = out_degree_non_fraud_loc_d
                                          )
  
return(sample_network_feature_df) 
  
  
  
  }

#directed_network_feature_df <-  directed_network_feature_function(sub_graph = sample_network_directed_weighted, verbose = T)


```


# 3.4 Feature extraction - Transactional data function(s)

```{r, Feature extraction - Transactional data }

#### Transaction feature generation function ####

# Description: The function will take as input the accounts_df and the transactions df and output the metrics  

# input: accounts_df and the transactions df
# output: a data frame containing transaction metrics 

transaction_feature_function <- function(transaction_df, accounts_df){ 
  
  # Can drill each of down into fraud and non-fraud
  
  # 1. Generating incoming transaction stats
  
  # basic incoming stats
  incoming_transaction_stats <- transaction_df %>% 
    mutate(is_round = if_else(plyr::round_any(weight, 10) == weight, T, F)) %>% 
    group_by(to) %>% 
    summarise(incoming_total = sum(weight),
              incoming_avg = mean(weight),
              incoming_sd = sd(weight),
              incoming_median = median(weight),
              incoming_max = max(weight),
              incoming_min = min(weight),
              incoming_round_numbers_count = sum(is_round))
  
  # fraud/non-fraud incoming transaction totals - receiving from fraudsters/non-fraudsters
  incoming_transactions_fraud_non_fraud <- transaction_df %>% 
    rename(client_ID = from) %>% 
    left_join(accounts_df, by = "client_ID")%>% 
    group_by(to, is_fraud) %>% 
    summarise(total = sum(weight)) %>% 
    pivot_wider(names_from = is_fraud,
                values_from = total) %>% 
    rename(fraud_total_income = `TRUE`,
           non_fraud_total_income = `FALSE`)
  
  # removing NA's
  incoming_transactions_fraud_non_fraud[is.na(incoming_transactions_fraud_non_fraud)] <- 0
  
  # joining and creating final df 
  incoming_transaction_stats_final <- left_join(incoming_transaction_stats,incoming_transactions_fraud_non_fraud, by = "to" ) %>% 
    rename(client_ID = to)
  
  
  # 2. Generating outgoing transaction stats
  
  # basic outgoing stats
  outgoing_transaction_stats <- transaction_df %>% 
    mutate(is_round = if_else(plyr::round_any(weight, 10) == weight, T, F)) %>%
    group_by(from) %>% 
    summarise(outgoing_total = sum(weight),
              outgoing_avg = mean(weight),
              outgoing_sd = sd(weight),
              outgoing_median = median(weight),
              outgoing_max = max(weight),
              outgoing_min = min(weight),
              outgoing_round_numbers_count = sum(is_round))
  
  # fraud/non-fraud incoming transaction totals - paying fraudsters/non-fraudsters
  outgoing_transactions_fraud_non_fraud <- transaction_df %>% 
    rename(client_ID = to) %>% 
    left_join(accounts_df, by = "client_ID")%>% 
    group_by(from, is_fraud) %>% 
    summarise(total = sum(weight)) %>% 
    pivot_wider(names_from = is_fraud,
                values_from = total) %>% 
    rename(total_fraud_payments = `TRUE`,
           total_non_fraud_payments = `FALSE`)
  
  # removing NA's
  outgoing_transactions_fraud_non_fraud[is.na(outgoing_transactions_fraud_non_fraud)] <- 0
  
  # joining and creating final df 
  outgoing_transaction_stats_final <- left_join(outgoing_transaction_stats,outgoing_transactions_fraud_non_fraud, by = "from" ) %>% 
    rename(client_ID = from)
  
  # 4. Creating transaction feature df
  
  transaction_feature_df <- data.frame(client_ID = accounts_df$client_ID,
                                       init_balance = accounts_df$init_balance)
  
  transaction_feature_df <- left_join(transaction_feature_df, incoming_transaction_stats_final, by = "client_ID") %>% 
    left_join(outgoing_transaction_stats_final, by = "client_ID")
  
  # replacing NA values
  
  cols_to_replace <- c("incoming_total", "incoming_avg", "incoming_max", "incoming_min", "incoming_round_numbers_count", "non_fraud_total_income", "fraud_total_income" , "outgoing_total", "outgoing_avg", "outgoing_max", "outgoing_min", "outgoing_round_numbers_count", "total_non_fraud_payments", "total_fraud_payments")
  
  transaction_feature_df[cols_to_replace][is.na(transaction_feature_df[cols_to_replace])] <- 0
  
  # Note: SD and Medians have NA values
  
  return(transaction_feature_df)
  
}


#transaction_df <- transaction_feature_function(transaction_df = edge_df,accounts_df = node_df  ) 


```


# 3.5  Constructing final feature data table

The below code chunk will define a function that will:
- Extract the transaction features from data
- Construct the needed type of networks (weighted-undirected network & Directed network)
- For each grapgh component (V > 2) extract the weighted-undirected features & directed features

```{r, constructing final feature data table}

# 1. Defining function that outputs final pre-processed data

feature_generation_func <- function(final_transactional_df, final_accounts_df) {
  
  # 1. Extracting transaction features
  
  print("*** Generating transactional data features ***")
  
  transaction_feature_df <- transaction_feature_function(transaction_df = final_transactional_df , accounts_df = final_accounts_df)
  transaction_feature_df$client_ID <- as.character(transaction_feature_df$client_ID)
  
  # 2. Constructing needed networks
  
  print("*** Constructing networks ***")
  
  # 2.1 Un-directed-weighted network
  
  # constructing raw network
  undirected_weighted_graph_raw <- graph_from_data_frame(d = final_transactional_df,
                                                               directed = F,
                                                               vertices = final_accounts_df) 
  
  # Simplifying the graph (removing multiple edges)
  undirected_weighted_graph_simp <- simplify(undirected_weighted_graph_raw,
                                                   remove.multiple = T,
                                                   remove.loops = T,
                                                   edge.attr.comb = c(weight = "sum"))
  
  # 2.2 Directed graph
  
  weight_ind <- which(names(final_transactional_df) == 'weight')
  
  directed_graph <- graph_from_data_frame(d = final_transactional_df[,-weight_ind],
                                                directed = T,
                                                vertices = final_accounts_df)
  
  # 3. Extract the network features for each component in the generated  graphs
  
  print("*** Extracting network features from each component in the graph(s) ***")
  
  # 3.1 Un-directed weighted graph
  
  print("* Un-direceted weighted graph  *")
  
  # decomposing graph into its graph components
  undirected_weighted_graph_components <- decompose.graph(graph = undirected_weighted_graph_simp,
                                                                min.vertices = 3) 
  
  # creating loop to extract the network features from each graph component
  
  undirected_weighted_graph_features <- data.frame()
  
  for (i in 1:length(undirected_weighted_graph_components)) {
    
    print(paste0("Busy with graph component ", i) )
    
    # assigning the ith component
    current_undirected_weighted_component <- undirected_weighted_graph_components[[i]]
    
    # extracting network features
    current_undirected_weighted_graph_features <- undirected_weighted_network_feature_func(sub_graph = current_undirected_weighted_component, verbose = T)
    
    # constructing final feature df
    undirected_weighted_graph_features <- rbind(undirected_weighted_graph_features, current_undirected_weighted_graph_features)
  
  }
  
  # Note: The number of accounts we are investigating decreased due to graph components that have less than 3 vertices are ommitted
  
  # 3.2 Directed graph
  
  print("* Direceted graph  *")

  # decomposing graph into its graph components
  directed_graph_components <- decompose.graph(graph = directed_graph,
                                                     min.vertices = 3) 
  
  # Note: Multiple graph components identified
  
  # creating loop to extract the network features from each graph component
  
  directed_graph_features <- data.frame()
  
  for (i in 1:length(directed_graph_components)) {
    
    print(paste0("Busy with graph component ", i) )
    
    # assigning the ith component
    current_directed_component <- directed_graph_components[[i]]
    
    # extracting network features
    current_directed_graph_features <- directed_network_feature_function(sub_graph = current_directed_component, verbose = T)
    
    # constructing final feature df
    directed_graph_features <- rbind(directed_graph_features, current_directed_graph_features)
    
  }

  
  # 4. Combing generated data tables into one feature df
  
  print("*** Creating feature data tables  ***")
  
  client_df <- data.frame(client_ID = as.character(final_accounts_df$client_ID),
                               is_fraud = final_accounts_df$is_fraud)
  
  network_feature_df <- left_join(undirected_weighted_graph_features, directed_graph_features, by = "client_ID") %>%  
    left_join(client_df, by = "client_ID")
  
  network_feature_clients <- data.frame(client_ID = network_feature_df$client_ID)
  
  transaction_feature_df <- left_join(network_feature_clients, transaction_feature_df, by = "client_ID") %>% 
    left_join(client_df, by = "client_ID")

  feature_tables <- list(network_features = network_feature_df,
                         transactional_features = transaction_feature_df) 
  
  return(feature_tables)
  
}



# 2. Configuring training data features

training_features <- feature_generation_func(final_transactional_df = training_transactions_final,
                                             final_accounts_df = training_accounts_final)

train_network_features <- training_features$network_features
train_transactional_features <- training_features$transactional_features

train_fraud_ind <- which(names(train_network_features) == "is_fraud")
train_all_features <- left_join(train_network_features[,-train_fraud_ind], train_transactional_features, by = "client_ID")

# 3. Configuring testing data features

testing_features <- feature_generation_func(final_transactional_df = testing_transactions_final,
                                             final_accounts_df = testing_accounts_final)

test_network_features <- testing_features$network_features
test_transactional_features <- testing_features$transactional_features

test_fraud_ind <- which(names(train_network_features) == "is_fraud")
test_all_features <- left_join(test_network_features[,-test_fraud_ind], test_transactional_features, by = "client_ID")


```

# 4. Post-local-EDA

# 5. Global EDA (network features evolving over time)

# 6. Model construction

In the following code chunks we will examine the performance of different models if 
i) Only using network features as inputs
ii) Only using transactional features as inputs
iii) Using network and transactional features


# 6.1 Logistic regression

```{r, model construction - logistic regression}

# 1. Applying final data-pre processing for LR model

# transforming response to factor variable
train_network_features$is_fraud <- as.factor(train_network_features$is_fraud)
train_transactional_features$is_fraud <- as.factor(train_transactional_features$is_fraud)
train_all_features$is_fraud <- as.factor(train_all_features$is_fraud)

test_network_features$is_fraud <- as.factor(test_network_features$is_fraud)
test_transactional_features$is_fraud <- as.factor(test_transactional_features$is_fraud)
test_all_features$is_fraud <- as.factor(test_all_features$is_fraud)

# omitting all columns that have NA values
train_transactional_features <- train_transactional_features[, colSums(is.na(train_transactional_features)) == 0]
train_all_features <- train_all_features[, colSums(is.na(train_all_features)) == 0]

test_transactional_features <- test_transactional_features[, colSums(is.na(test_transactional_features)) == 0]
test_all_features <- test_all_features[, colSums(is.na(test_all_features)) == 0]

# 2. Constructing standard logistic regression models

# network features LR model
log_std_model_network <- glm(is_fraud ~ . , data = train_network_features[,-1], family = "binomial")
summary(log_std_model_network)
round(exp(coef(log_std_model_network)),3)

# transactional features LR model
log_std_model_trans <- glm(is_fraud ~ . , data = train_transactional_features[,-1], family = "binomial")
summary(log_std_model_trans)
round(exp(coef(log_std_model_trans)),3)

# all features LR model
log_std_model_all <- glm(is_fraud ~ . , data = train_all_features[,-1], family = "binomial")
summary(log_std_model_all)
round(exp(coef(log_std_model_all)),3)

# 3. Constructing logistic regression with LASSO penalty

# network features
log_LASSO_model_network <- glmnet(x = as.matrix(train_network_features[,-c(1,ncol(train_network_features))]),
                                                y = train_network_features$is_fraud , 
                                                alpha = 1, 
                                                standardize = TRUE, 
                                                family = 'binomial')

plot(log_LASSO_model_network, xvar = 'lambda', label=TRUE)

# transactional features

log_LASSO_model_trans <- glmnet(x = as.matrix(train_transactional_features[,-c(1,ncol(train_transactional_features))]),
                                                y = train_transactional_features$is_fraud, 
                                                alpha = 1, 
                                                standardize = TRUE, 
                                                family = 'binomial')

plot(log_LASSO_model_trans, xvar = 'lambda', label=TRUE)

# all features

log_LASSO_model_all <- glmnet(x = as.matrix(train_all_features[,-c(1,ncol(train_all_features))]),
                                                y = train_all_features$is_fraud, 
                                                alpha = 1, 
                                                standardize = TRUE, 
                                                family = 'binomial')

plot(log_LASSO_model_all, xvar = 'lambda', label=TRUE)



# 3.1 Applying 10-fold CV to determine optimal lambda value

# network features
log_cv_model_network <- cv.glmnet(x = as.matrix(train_network_features[,-c(1,ncol(train_network_features))]),
                               y = train_network_features$is_fraud,
                               alpha = 1, # LASSO
                               nfolds = 10,
                               type.measure = "mse",
                               family = "binomial",
                               standardize = T)

plot(log_cv_model_network)
log_cv_model_network$lambda.1se

# transactional features
log_cv_model_trans <- cv.glmnet(x = as.matrix(train_transactional_features[,-c(1,ncol(train_transactional_features))]),
                               y = train_transactional_features$is_fraud,
                               alpha = 1, # LASSO
                               nfolds = 10,
                               type.measure = "mse",
                               family = "binomial",
                               standardize = T)

plot(log_cv_model_trans)
log_cv_model_trans$lambda.1se

# all features
log_cv_model_all <- cv.glmnet(x = as.matrix(train_all_features[,-c(1,ncol(train_all_features))]),
                               y = train_all_features$is_fraud,
                               alpha = 1, # LASSO
                               nfolds = 10,
                               type.measure = "mse",
                               family = "binomial",
                               standardize = T)

plot(log_cv_model_all)
log_cv_model_all$lambda.1se


# 4. Probability Predictions

# 4.1 Training set

# 4.1.1 Network features

# Regular LR model
pi_hat_log_std_network <- predict(log_std_model_network, type = "response")

# LASSO LR model
pi_hat_log_lasso_network <- predict(log_cv_model_network, 
                                    newx = as.matrix(train_network_features[,-c(1,ncol(train_network_features))]),
                                    s = log_cv_model_network$lambda.1se,
                                    type = "response")


# 4.1.2 Transactions features

# Regular LR model
pi_hat_log_std_trans <- predict(log_std_model_trans, type = "response")

# LASSO LR model
pi_hat_log_lasso_trans <- predict(log_cv_model_trans, 
                                    newx = as.matrix(train_transactional_features[,-c(1,ncol(train_transactional_features))]),
                                    s = log_cv_model_trans$lambda.1se,
                                    type = "response")


# 4.1.3 all features
pi_hat_log_std_all <- predict(log_std_model_all, type = "response")

# LASSO LR model
pi_hat_log_lasso_all <- predict(log_cv_model_all, 
                                    newx = as.matrix(train_all_features[,-c(1,ncol(train_all_features))]),
                                    s = log_cv_model_all$lambda.1se,
                                    type = "response")


# determining optimal threshold value

## ROC curves

### Network features

# standard LR
pred_std_network <- prediction(pi_hat_log_std_network, train_network_features$is_fraud)
perf_std_network <- performance(pred_std_network, "tpr", "fpr")
plot(perf_std_network, colorize = FALSE, col = 'black')
lines(c(0,1), c(0,1), col = 'gray', lty = 4)
performance(pred_std_network, measure = 'auc')@y.values[[1]]


# LASSO LR
pred_lasso_network <- prediction(pi_hat_log_lasso_network, train_network_features$is_fraud)
perf_lasso_network <- performance(pred_lasso_network, "tpr", "fpr")
plot(perf_lasso_network, colorize = FALSE, col = 'black')
lines(c(0,1), c(0,1), col = 'gray', lty = 4)
performance(pred_lasso_network, measure = 'auc')@y.values[[1]]


### Transactional features

# standard LR
pred_std_trans <- prediction(pi_hat_log_std_trans, train_transactional_features$is_fraud)
perf_std_trans <- performance(pred_std_trans, "tpr", "fpr")
plot(perf_std_trans, colorize = FALSE, col = 'black')
lines(c(0,1), c(0,1), col = 'gray', lty = 4)
performance(pred_std_trans, measure = 'auc')@y.values[[1]]


# LASSO LR
pred_lasso_trans <- prediction(pi_hat_log_lasso_trans, train_transactional_features$is_fraud)
perf_lasso_trans <- performance(pred_lasso_trans, "tpr", "fpr")
plot(perf_lasso_trans, colorize = FALSE, col = 'black')
lines(c(0,1), c(0,1), col = 'gray', lty = 4)
performance(pred_lasso_trans, measure = 'auc')@y.values[[1]]

### all features

# standard LR
pred_std_all <- prediction(pi_hat_log_std_all, train_all_features$is_fraud)
perf_std_all <- performance(pred_std_all, "tpr", "fpr")
plot(perf_std_all, colorize = FALSE, col = 'black')
lines(c(0,1), c(0,1), col = 'gray', lty = 4)
performance(pred_std_all, measure = 'auc')@y.values[[1]]


# LASSO LR
pred_lasso_all <- prediction(pi_hat_log_lasso_all, train_all_features$is_fraud)
perf_lasso_all <- performance(pred_lasso_all, "tpr", "fpr")
plot(perf_lasso_all, colorize = FALSE, col = 'black')
lines(c(0,1), c(0,1), col = 'gray', lty = 4)
performance(pred_lasso_all, measure = 'auc')@y.values[[1]]



# NB! FOR EACH MODEL DETERMINE THE OPTIMAL THRESHOLD!!! - continue here


## precision and recall curves











### NETWORK METRICS - OLD ###

# 1. Creating network feature df and configuring predictors and response variables

# 1.1 Joining netwotk feature df's
final_network_feature_df_train <- left_join(undirected_weighted_graph_features_train, directed_graph_features_train, by = "client_ID") %>% 
  left_join(fraud_df_train, by = "client_ID")

final_network_feature_df_train$is_fraud <- as.factor(if_else(final_network_feature_df_train$is_fraud == T, "T", "F"))

# 1.2 Configuring predictors
x_train <- as.matrix(final_network_feature_df_train[,-c(1,ncol(final_network_feature_df_train))])
y_train <- final_network_feature_df_train$is_fraud

# 2. Training logistic regression model wit LASSO reguliser - without using SMOTE

# 2.2 fitting model(s)

# fitting standard logistic regression (LR) model

std_log_reg_model <- glm(is_fraud~., data = final_network_feature_df_train[,-1],
                          family = "binomial")


# Applying LASSO and determining lambda using 10-fold cross validation

lasso_cv_log_reg_model <- cv.glmnet(x = x_train, y = y_train, 
                    alpha = 1,
                    type.measure = 'class',
                    standardize = T, 
                    family = 'binomial',
                    nfolds = 10)


# 2.3 Making predictions

# standard LR
pi_hat_std_LR <- predict(std_log_reg_model, type = "response", newx = x_train)

# LR model (LASSO applied with lambda chosen by CV)
pi_hat_lasso_LR <- predict(lasso_cv_log_reg_model, s = lasso_cv_log_reg_model$lambda.1se,  type = "response", newx = x_train)


# Assign threshold of 0.5 to classifiers arbitrarily

Y_hat_std <- ifelse(pi_hat_std_LR >= 0.5, "T", "F")
Y_hat_cv <- ifelse(pi_hat_lasso_LR >= 0.5, "T", "F")

# 2.4 Evaluating results


# 2.4.1 confusion matrix

table(Y_hat_std, y_train)

table(Y_hat_cv, y_train)


# creating prediction object
pred_std_LR <- prediction(pi_hat_std_LR, )





















```






### DEMO CODE ###

Tests code

```{r, test code}

####


  
  





####

time_stamp <- transactions_data_raw %>% 
  group_by(TIMESTAMP) %>% 
  summarise(count = n())

time_stamp %>% 
ggplot(aes(x = TIMESTAMP, y = count)) + 
  geom_col()

hist(time_stamp$count)

plot(density(time_stamp$count))

sum(time_stamp$count)*0.75


# splitting the data (out-of-time validation)

transactions_test <- transactions_data_raw %>% 
  mutate(row_index  = 1:nrow(transactions_data_raw)) %>% 
  mutate(set = if_else(row_index < 0.5480962*nrow(transactions_data_raw), "train", "test"))


# visualing some data

transactions_test %>%
  group_by(IS_FRAUD, set) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x = set, y = count, fill = IS_FRAUD )) +
  geom_bar(stat="identity", position=position_dodge()) +
  geom_text(aes(label=count), vjust=1.6, position = position_dodge(0.9), size=3.5) +
  scale_y_log10()


# optimiser

split_point_df <- data.frame(split = seq(from = 0.5, to = 0.8, length.out = 500))

transactions_test <- transactions_data_raw %>% 
  mutate(row_index  = 1:nrow(transactions_data_raw))

test_fraud_ratio <- rep(NA, nrow(split_point_df))

train_fraud_ratio <- rep(NA, nrow(split_point_df))

resulting_ratio <- rep(NA, nrow(split_point_df))

for (i in 1:nrow(split_point_df)) {
  
  
  current_split <- transactions_test %>% 
    mutate(set = if_else(row_index < split_point_df[i,1]*nrow(transactions_data_raw), "train", "test")) %>% 
    group_by(set, IS_FRAUD) %>% 
    summarise(current_count = n())
  
  # test
  test_fraud_total <- current_split$current_count[current_split$set == "test" &  current_split$IS_FRAUD == "True"]
  test_non_fraud_total <- current_split$current_count[current_split$set == "test" &  current_split$IS_FRAUD == "False"]
  
  test_fraud_ratio[i] <-  test_fraud_total/(test_fraud_total + test_non_fraud_total)
  
  train_fraud_total <- current_split$current_count[current_split$set == "train" &  current_split$IS_FRAUD == "True"]
  train_non_fraud_total <- current_split$current_count[current_split$set == "train" &  current_split$IS_FRAUD == "False"]
  
  train_fraud_ratio[i] <-  train_fraud_total/(train_fraud_total + train_non_fraud_total)
  
  resulting_ratio[i] <- test_fraud_ratio[i] - train_fraud_ratio[i]
  
  
}

split_point_df$test_fraud_ratio <- test_fraud_ratio

split_point_df$train_fraud_ratio <- train_fraud_ratio

split_point_df$resulting_ratio <- resulting_ratio


split_point_df %>% 
  ggplot(aes(x = split, y = resulting_ratio)) +
  geom_point()


split_point_df_filt <- split_point_df %>% 
  filter(resulting_ratio >= 0 )


which(split_point_df_filt$resulting_ratio == min(split_point_df_filt$resulting_ratio))



```


Unused code
```{r, unused code}

###### 1. TEST TRAIN SPLIT ###### 

# split should be:

# 3.1 Stratified splitting of data - 

set.seed(123)
train_index <- createDataPartition(accounts_data_final$is_fraud, p = 0.8, list = F)


# accounts data

accounts_data_final_train <- accounts_data_final[train_index,]
accounts_data_final_test <- accounts_data_final[-train_index,]

# transaction data 

# configuring training data set 
transactions_data_final_train <- transactions_data_final %>% 
  filter(to %in% accounts_data_final_train$client_ID & from %in% accounts_data_final_train$client_ID)

transactions_data_final_test <- transactions_data_final 

# 3. Data split

# split should be:

# 3.1 Stratified splitting of data - 

set.seed(123)
train_index <- createDataPartition(accounts_data_final$is_fraud, p = 0.8, list = F)


# accounts data

accounts_data_final_train <- accounts_data_final[train_index,]
accounts_data_final_test <- accounts_data_final[-train_index,]

# transaction data 

# configuring training data set 
transactions_data_final_train <- transactions_data_final %>% 
  filter(to %in% accounts_data_final_train$client_ID & from %in% accounts_data_final_train$client_ID)

transactions_data_final_test <- transactions_data_final 


#### NEW: Splitting the data based on time stamp variable ###

# grouping the number of transactions per time stamp
transactions_time_stamp <- transactions_data_final %>% 
  group_by(TIMESTAMP) %>% 
  summarise(count = n())

# calculating cumulative count
total_count <- sum(transactions_time_stamp$count)
cum_count <- rep(NA, nrow(transactions_time_stamp))
cum_perc <- rep(NA, nrow(transactions_time_stamp)) 

for (i in 1:nrow(transactions_time_stamp)) {
  
  if(i == 1) {
    
  cum_count[i] <- transactions_time_stamp$count[i]
  cum_perc[i] <- 0
  
  }else{
    
    cum_count[i] <- cum_count[i-1] + transactions_time_stamp$count[i]
    cum_perc[i] <- round((cum_count[i]/total_count)*100, 2)
  }
}

# selecting the time stamp that contains 75% of all the observations (for training)

training_ind <- max(which(cum_perc < 76))
training_time_stamp <- transactions_time_stamp$TIMESTAMP[training_ind]

# defining training set for transactions
training_transactions <- transactions_data_final %>% 
  filter(TIMESTAMP <= training_time_stamp)

# defining training set for accounts

training_unique_acc_id <- unique(c(training_transactions$from,training_transactions$to)) 

# defining training fraudulent accounts

training_fraud_acc <- training_transactions %>% 
  filter(IS_FRAUD == "True")

training_fraud_acc <- unique(c(training_fraud_acc$from, training_fraud_acc$to))

# defining accounts df

training_accounts <- 




time_stamp %>% 
ggplot(aes(x = TIMESTAMP, y = count)) + 
  geom_col()

hist(time_stamp$count)

plot(density(time_stamp$count))

sum(time_stamp$count)*0.75


# splitting the data (out-of-time validation)

transactions_test <- transactions_data_raw %>% 
  mutate(row_index  = 1:nrow(transactions_data_raw)) %>% 
  mutate(set = if_else(row_index < 0.5480962*nrow(transactions_data_raw), "train", "test"))


# visualing some data

transactions_test %>%
  group_by(IS_FRAUD, set) %>% 
  summarise(count = n()) %>% 
  ggplot(aes(x = set, y = count, fill = IS_FRAUD )) +
  geom_bar(stat="identity", position=position_dodge()) +
  geom_text(aes(label=count), vjust=1.6, position = position_dodge(0.9), size=3.5) +
  scale_y_log10()


# optimiser

split_point_df <- data.frame(split = seq(from = 0.5, to = 0.8, length.out = 500))

transactions_test <- transactions_data_raw %>% 
  mutate(row_index  = 1:nrow(transactions_data_raw))

test_fraud_ratio <- rep(NA, nrow(split_point_df))

train_fraud_ratio <- rep(NA, nrow(split_point_df))

resulting_ratio <- rep(NA, nrow(split_point_df))

for (i in 1:nrow(split_point_df)) {
  
  
  current_split <- transactions_test %>% 
    mutate(set = if_else(row_index < split_point_df[i,1]*nrow(transactions_data_raw), "train", "test")) %>% 
    group_by(set, IS_FRAUD) %>% 
    summarise(current_count = n())
  
  # test
  test_fraud_total <- current_split$current_count[current_split$set == "test" &  current_split$IS_FRAUD == "True"]
  test_non_fraud_total <- current_split$current_count[current_split$set == "test" &  current_split$IS_FRAUD == "False"]
  
  test_fraud_ratio[i] <-  test_fraud_total/(test_fraud_total + test_non_fraud_total)
  
  train_fraud_total <- current_split$current_count[current_split$set == "train" &  current_split$IS_FRAUD == "True"]
  train_non_fraud_total <- current_split$current_count[current_split$set == "train" &  current_split$IS_FRAUD == "False"]
  
  train_fraud_ratio[i] <-  train_fraud_total/(train_fraud_total + train_non_fraud_total)
  
  resulting_ratio[i] <- test_fraud_ratio[i] - train_fraud_ratio[i]
  
  
}

split_point_df$test_fraud_ratio <- test_fraud_ratio

split_point_df$train_fraud_ratio <- train_fraud_ratio

split_point_df$resulting_ratio <- resulting_ratio


split_point_df %>% 
  ggplot(aes(x = split, y = resulting_ratio)) +
  geom_point()


split_point_df_filt <- split_point_df %>% 
  filter(resulting_ratio >= 0 )


which(split_point_df_filt$resulting_ratio == min(split_point_df_filt$resulting_ratio))

###### 1. TEST TRAIN SPLIT ###### 



#### Period stats (in funcrion) ####


# 3. Generating time period stats for accounts
  
  # 3.1 payment made (to)
  
  # all accounts that made a payment
  payment_IDs <- unique(transaction_df$from)
  
  # data frame that stores the results
  payment_period_stats_df <- data.frame(client_ID = payment_IDs,
                                        payment_period_max = rep(NA, length(payment_IDs)),
                                        payment_period_min = rep(NA, length(payment_IDs)),
                                        payment_period_avg = rep(NA, length(payment_IDs)),
                                        payment_period_std = rep(NA, length(payment_IDs)))
  
  
  for (i in 1:length(payment_IDs)) {
    
    # filtering a specific account that made payment(s)
    current_df <- transaction_df %>% 
      filter(from == payment_IDs[i]) %>% 
      arrange(tran_timestamp)
    
    if(nrow(current_df) > 1){
      
      # creating vector that stores the time difference between payments made by account
      current_days_difference <- rep(NA,nrow(current_df))
      
      for (j in 2:nrow(test_df)) {
        
        current_days_difference[j] <- difftime(current_df$tran_timestamp[j],current_df$tran_timestamp[j-1], units = "days")
        
      }
      
      # saving stats variables to created data frame
      payment_period_stats_df$payment_period_max[i] <- max(current_days_difference, na.rm =T)
      payment_period_stats_df$payment_period_min[i] <- min(current_days_difference, na.rm =T) 
      payment_period_stats_df$payment_period_avg[i] <- mean(current_days_difference, na.rm =T) 
      payment_period_stats_df$payment_period_std[i] <- sd(current_days_difference, na.rm =T) 
      
    }else{
      
      # saving stats variables to created data frame
      payment_period_stats_df$payment_period_max[i] <- 1
      payment_period_stats_df$payment_period_min[i] <- 1 
      payment_period_stats_df$payment_period_avg[i] <- 1 
      payment_period_stats_df$payment_period_std[i] <- 0 
      
      
      
      
    }
    
    
  }


```


Visualisations ideas
```{r, visulaisation ideas}

# visualizing weights

## box plot
boxplot(log(transactions_data_weighted$weight))

## histogram
ggplot(transactions_data_weighted, aes(x= weight)) +
  geom_histogram() +
  scale_y_log10()


# 2. Constructing un-directed weighted network 
AML_net_uw_non_simple <- graph_from_data_frame(d = transactions_data_weighted,
                                 vertices = accounts_data_up,
                                 directed = FALSE)



# degree visualizations:

# Standard degree

## histogram ()
hist(total_degree_loc, main="Histogram of Total Node Degree", xlab = "Total Degree")

## density plot
density_degree <- density(total_degree_loc)
plot(density_degree, main="Density distribution of node degree")

# Weighted degree distribution

## histogram ()
hist(weighted_degree_distribution, main="Histogram of Weighted Degree Dsitribution", xlab = "Weighted Degree")

## density plot
density_weight_degree <- density(weighted_degree_distribution)
plot(density_weight_degree, main="Density distribution of weighted node degree")

```






